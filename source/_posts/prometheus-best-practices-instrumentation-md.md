---
title: 监控手段
date: 2019-12-22 23:43:28
tags: 
 - prometheus
 - best practices
 - instrumentation
 - 最佳实践
---

## 0x0

本文对如何设计监控方面,提供了一些意见性的指导建议。

本文章翻译自Prometheus官方文档：[Best Pratices-INSTRUMENTATION](https://prometheus.io/docs/practices/instrumentation/#how-to-instrument)


## 0x1 怎么监控？
简单的来说，就是监控一切：对于任何一个库(Library)，子系统(SubSystem)或者服务(Service)来说，都至少应该有几个指标来告诉你他们现在运行状况。数据采集部分应该是代码里不可或缺的一部分。这能够在你调查错误的时候，更容易的从告警着手，进而联系到控制台和代码。

### 服务可以被分为三类
根据监控的目地，服务通常可以被划分到以下三类之中：在线服务、离线服务以及批处理任务。虽然这三种服务的定义互相略有重叠，但是基本上所有的服务都可以很好的被归入其中之一里去。

#### 在线服务
如果一个人或者其他系统期望在这个系统里能够立即得到响应，那么这个系统就是一个在线系统。打一个比方，大部分的数据库、HTTP服务都归于此类。

这种系统的关键监控指标就是已经发生的“查询（query）数量”、“错误(error)数量”以及“延迟(latency)”。同样的，这些数字指标套用在正在处理中的请求上，也是十分具有意义的。

对于对错误监控方面的建议，请直接参考下文的[错误](#Failures)章节。

对于是属于“在线服务”类的系统而言，应该同时监控它的服务端和客户端。因为如果看到两边的东西不一样了，那么这个事情对于Debug是非常有帮助的信息。不过如果一个服务端同时服务了太多的客户端，以至于服务端无法一一地去追踪客户端的状态，那么客户端也只能依靠它们自己的状态了。

另外，在对查询（query）计数的时候，要么全部在一开始，要么都在结束后。 在结束后进行计数是比较推荐的，因为这能够对错误和延迟状况进行描绘，写起代码来也更简单。

#### 离线服务
对于离线服务而言，不会有人一直会等待响应回来。而且这种情况下，任务基本上是成批处理的，而且基本上处理过程都得分为好几个阶段。

针对每一个阶段，追踪每一个扇入的任务，有多少个任务正在处理，上次处理了一些东西之后扇出了多少任务。如果是批量处理的，那对进出的批次也应该追踪起来。

知道“上一次系统处理了一些东西”这个信息对判断系统有没有挂掉是一个很有用的信息，但是这个信息具有很大的局限性。更好的做法是将心跳信息贯穿整个系统：加入一些带有时间戳的虚拟任务，并将这些任务在系统内一直传递下去。每个处理阶段都把他们看到的任务时间戳通过心跳的方式暴露出来。如果对于在没有任务处理时不存在静默期的系统，就不需要其他明确的心跳信息了。

#### 批处理任务
对于离线任务和批处理任务而言，界限是比较模糊的。这是因为离线处理就很有可能是通过批处理来实现的。因为批处理任务有一个非持续运行的特点，导致了收集他们的信息十分的困难。

对于批处理任务而言，关键的指标就是上次任务成功的时间。另外，追踪任务在每一个处理阶段所花费的时间，总体的运行时间以及上次任务完成时间（无论是成功还是失败）都是很有帮助的。对于这些数据而言，这些全都是Gauge类型的，而且这些都应该直接推到PushGateway里从而完成收集。另外在通常情况下，一些总体性的与任务相关的数字也是很有意义的，例如已处理的任务总数之类的。

针对那些只跑要跑好几分钟的批量任务而言，用基于拉的监控方式来搞也挺有用的。这可以让你观察到同一个监控指标在执行不同类型的任务的时候的区别，例如资源使用率，与其他系统交互时候的延迟等等。这些信息对于调查诸如任务处理开始变慢的问题的时候，是非常具有参考意义的。

针对于那些跑得非常频繁（一般来说，小于15分种跑一次就算频繁）的任务而言，你就应该考虑将这些任务转换成后台服务，并将其当作离线任务来处理。

### 子系统（SubSystem）
除了三种基本服务以外，系统中也有一些部分需要被监控起来。

#### 依赖库（Libraries）
依赖库应该提供一些无需用户额外配置的监控方式。

如果一个库是用来从外部去拿一些资源信息的（比如网络，磁盘，IPC等），理应对他们总体的每分钟查询数量，错误数量（如果有可能发生）以及延迟情况。

取决于被依赖的库有多重，诸如追踪库内部产生的内部错误以及延迟情况等任何你认为有用的通用统计数据。

一个依赖库也很有可能被一个应用的完全不同的部分独立的使用了，所以注意使用合适的标签（Label）来区分彼此。 打一个比方：一个数据库链接池应该以它连接到的数据库来区分，然而对于DNS客户端库而言就没必要进行区分了。

#### 日志
有一个通用规则：对于每一条日志而言你都应该对于有一个自增的计数器来计数。这是因为，如果你对某条日志比较感兴趣的时候，你很有可能会想知道它多久发生一次，以及每次发生持续多久。

如果在一个函数里有多个很接进的日志信息（例如在If/Switch的不同分支里），那么这时候也可以用一个计数器来代表所有日志。

通常情况下，对应用的INFO/ERROR/WARNING日志总条目进行计数是很有用的，这能够用于在发布过程中检查其有没有较大的差异。

#### 错误处理
错误的处理应该和日志比较相近。每次有错误发生，一个计数器就应该自增。但是和日志不同的是，错误通常会向上传递到一个更宽泛的错误计数器之上，这通常取决于你的代码结构。

当汇报错误的时候，你通常应该有一些其余的代表总共的尝试次数的指标，从而能够用这些信息来计算出错误率。

#### 线程池
对于任何类型的线程池，最重要的指标就是请求队列的深度，当前的线程数量，线程池线程的总数，处理的任务数量，以及处理任务所消耗的时间。当然，追踪任务在队列中等待的时间也有很有意义的。

#### 缓存
对于缓存来说，主要的监控指标是总查询次数，缓存命中次数，总体延迟时间。而对于任意在线系统前的缓存而言，则是查询次数，错误次数以及延迟。

#### 收集器（Collector）
对于实现一个较为重要的自定义指标收集器，其中有一条建议是收集任务每秒需要占用的时间以及记录下它所发生的错误次数，以Guage的心事导出。

只有两种情况下，可以将一个事情发生的持续时间用Guage形式导出，而这就是其中一种，而另外一种情况则是批处理任务的持续时间。这是因为这两种情况都代表了特定的推送/搜刮的信息，而不是要随着时间的推移追踪多个事件的持续时间。

### 应该注意的事项
这里有一些做监控的时候我们都应该注意的地方，但除此以外也还有一些与Prometheus特定相关的注意点。
#### 使用标签
#### 不要滥用标签
#### Counter vs. gauge, summary vs. histogram
#### 具体的时间戳，而非相对时间
#### 内层循环
#### 避免缺失指标